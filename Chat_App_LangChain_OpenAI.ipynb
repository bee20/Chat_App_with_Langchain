{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bee20/Chat_App_with_Langchain/blob/main/Chat_App_LangChain_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mXAwoTdc-KeU"
      },
      "outputs": [],
      "source": [
        "# install basic libraries\n",
        "# langchain helps you to create your own LLM models based on pretrained LLMs\n",
        "# it can various llm models like openai, hugging face etc\n",
        "!pip install langchain\n",
        "!pip install langchain_openai\n",
        "# provides access to open_ai\n",
        "!pip install openai\n",
        "# to read pdf\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "# for tokenization\n",
        "!pip install tiktoken\n",
        "\n",
        "# to load the online pdf\n",
        "!pip3 install unstructured\n",
        "!pip install pdf2image\n",
        "!pip3 install pdfminer.six\n",
        "!pip install pillow_heif\n",
        "!pip install pikepdf\n",
        "!pip install chromadb\n",
        "!pip install streamlit\n",
        "!pip install streamlit_extras\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrurAfp-BNyW"
      },
      "outputs": [],
      "source": [
        "# from dotenv import load_dotenv\n",
        "import pickle\n",
        "from streamlit_extras.add_vertical_space import add_vertical_space\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "# get openai embeddings\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# split content from pdf , example new line\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# this is like vector database, to store our pdf embeddings here in this database\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "# for password of the app\n",
        "import urllib\n",
        "\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain.llms import OpenAI\n",
        "# from langchain.chains.question_answering import load_qa_chain\n",
        "# from langchain.callbacks import get_openai_callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ou7HI_j-O9m"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create secret key in openai website, can get free credits to new users\n",
        "# this is to access gpt model\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "# os.environ[\"SERPAPI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdPx6vEJ-j0p",
        "outputId": "5237c841-da78-4b2a-96b3-322649362b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlQI57hhBd77"
      },
      "source": [
        "# **Make your own Chat App**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m1IOgqd0EX4",
        "outputId": "66ac3a23-903f-41ea-9354-01a9b3d25ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain.document_loaders import OnlinePDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_openai import ChatOpenAI\n",
        "# get openai embeddings\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# split content from pdf , example new line\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# this is like vector database, to store our pdf embeddings here in this database\n",
        "from langchain.vectorstores import FAISS\n",
        "# Sidebar contents\n",
        "with st.sidebar:\n",
        "    st.title('Your LLM Chat App')\n",
        "    st.markdown('''\n",
        "    ## About\n",
        "    This app is an LLM-powered chatbot built using:\n",
        "    - [Streamlit](https://streamlit.io/)\n",
        "    - [LangChain](https://python.langchain.com/)\n",
        "    - [OpenAI](https://platform.openai.com/docs/models) LLM model\n",
        "\n",
        "    ''')\n",
        "    st.write('By BB')\n",
        "# load_dotenv()\n",
        "\n",
        "st.header(\"Chat with your PDF ðŸ’¬\")\n",
        "# pdf = st.file_uploader(\"Upload your PDF\", type='pdf')\n",
        "query = st.text_input(\"Provide link to your PDF file:\")\n",
        "loader = OnlinePDFLoader(query)\n",
        "# data = loader.load()\n",
        "embeddings = OpenAIEmbeddings()\n",
        "query1 = st.text_input(\"Type in your query\")\n",
        "index = VectorstoreIndexCreator( embedding = embeddings).from_loaders([loader])\n",
        "# index.query(query)\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "response = index.query(query1, llm)\n",
        "st.write(response)\n",
        "\n",
        "# https://arxiv.org/pdf/1706.03762.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZTEa_kh032I",
        "outputId": "81acac48-f978-4d25-b83d-7e437ff8dee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.221.55.139\n"
          ]
        }
      ],
      "source": [
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xau_rTJRyB71",
        "outputId": "20d40be9-a14b-42bc-fb8b-4bde73fa9d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.309s\n",
            "your url is: https://yellow-animals-report.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31JdnKfwzVrk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce2-PMJKBamQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1guLhVfLBaid"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOahvT2TMJHZ0bMuzAjAF+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}